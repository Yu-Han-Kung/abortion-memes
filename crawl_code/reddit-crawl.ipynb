{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637ca322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(client_id='xxxxxxxx',\n",
    "                    client_secret='xxxxxxxxxxxx',\n",
    "                    user_agent='xxxxxxxxxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea388e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(reddit.read_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9c3c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#參數設定\n",
    "keywordlist = ['Abort', 'termination of pregnancy', 'terminate pregnancy',\n",
    "               'pregnancy termination', 'post-abortion', 'postabortion', \n",
    "               'roe v wade', 'prolife', 'right-to-life', 'anti-choice', \n",
    "               'pro-abortion', 'pro abortion','Dobbs v. Jackson',\n",
    "               'abortion']\n",
    "area = 'antimeme' # 'memes' 'dankmemes' politicalmemes antimeme meme\n",
    "\n",
    "#sort='hot' #手動添加\n",
    "#time_filter='year' #手動添加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaaa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm \n",
    "\n",
    "# 選擇一個subreddit\n",
    "subreddit = reddit.subreddit(area)\n",
    "\n",
    "# 定義要抓取的帖子數量\n",
    "#limit = 1000\n",
    "\n",
    "allmeme = 0\n",
    "\n",
    "for keyword in keywordlist:\n",
    "    \n",
    "    # 設定你想要檢查和創建的資料夾路徑\n",
    "    folder_path = 'reddit_' + area + '\\\\' + keyword + '\\\\'\n",
    "\n",
    "    # 檢查資料夾是否存在\n",
    "    if not os.path.exists(folder_path):\n",
    "        # 如果資料夾不存在，則創建它\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"資料夾 '{folder_path}' 已創建。\")\n",
    "    else:\n",
    "        # 如果資料夾已存在，則輸出提示信息\n",
    "        print(f\"資料夾 '{folder_path}' 已存在。\")\n",
    "\n",
    "    # 打開一個CSV文件以寫入\n",
    "    with open(folder_path + keyword +'.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # 寫入標題行\n",
    "        writer.writerow(['Title', 'URL', 'post url','Author', 'Score', \n",
    "                         'Subreddit', 'Created UTC', 'Selftext', \n",
    "                         'Num Comments', 'Upvote Ratio', 'Is Self','comment',\n",
    "                         'author_flair_text','clicked','distinguished',\n",
    "                         'edited','id','is_original_content','link_flair_text',\n",
    "                         'locked','name','over_18','permalink','saved','spoiler','stickied'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 获取subreddit的帖子列表\n",
    "        submissions = list(subreddit.search(keyword, limit=None)) #沒設limit=None會只有100則貼文\n",
    "        \n",
    "        # 使用tqdm包装submissions，以显示进度条\n",
    "        for submission in tqdm(submissions, desc='Processing submissions'):\n",
    "            \n",
    "            \n",
    "        # 遍歷subreddit的帖子sort=sort, time_filter=time_filter\n",
    "        #for submission in subreddit.search(keyword):\n",
    "            # 构建完整的Reddit帖子URL **取評論需要文章連結 直接用submission.url取到的圖片 .jpg/.png的連結\n",
    "            post_url = f\"https://www.reddit.com{submission.permalink}\"\n",
    "            \n",
    "            submissioncomment = reddit.submission(url=post_url)\n",
    "            # 在遍历评论之前，尝试加载所有可用的评论\n",
    "            submissioncomment.comments.replace_more(limit=None)\n",
    "            \n",
    "            commentlist = []\n",
    "\n",
    "            for comment in submissioncomment.comments.list():\n",
    "                if isinstance(comment, praw.models.MoreComments):\n",
    "                    continue  # 如果是MoreComments对象，跳过这个迭代\n",
    "                \n",
    "                commentpair = []\n",
    "                commentpair.append(comment.body)\n",
    "                commentpair.append(datetime.fromtimestamp(comment.created_utc).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                commentlist.append(commentpair)\n",
    "                \n",
    "            #把評論轉成json格式\n",
    "            comments_json = json.dumps(commentlist, ensure_ascii=False)\n",
    "                \n",
    "            # 轉換創建時間\n",
    "            created_time = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
    "            # 寫入每個帖子的資訊\n",
    "            writer.writerow([submission.title, \n",
    "                             submission.url,\n",
    "                             post_url,\n",
    "                             str(submission.author), \n",
    "                             submission.score,\n",
    "                             str(submission.subreddit), \n",
    "                             created_time, \n",
    "                             submission.selftext,\n",
    "                             submission.num_comments, \n",
    "                             submission.upvote_ratio, \n",
    "                             submission.is_self,\n",
    "                             commentlist,\n",
    "                             submission.author_flair_text, ##\n",
    "                             submission.clicked,\n",
    "                             submission.distinguished,\n",
    "                             submission.edited,\n",
    "                             submission.id,\n",
    "                             submission.is_original_content,\n",
    "                             submission.link_flair_text,\n",
    "                             submission.locked,\n",
    "                             submission.name,\n",
    "                             submission.over_18,\n",
    "                             submission.permalink,\n",
    "                             submission.saved,\n",
    "                             submission.spoiler,\n",
    "                             submission.stickied])\n",
    "\n",
    "\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    # 讀取CSV檔案\n",
    "    csv_file_path = folder_path + keyword +'.csv'\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    print('貼文數',len(df['URL']))\n",
    "\n",
    "    import requests\n",
    "    import time\n",
    "\n",
    "    error = []\n",
    "    memenumber = 0\n",
    "\n",
    "    for i in df['URL']:\n",
    "\n",
    "        try:\n",
    "\n",
    "            n = i.split('redd.it/')[1]\n",
    "\n",
    "            pic = requests.get(i)\n",
    "            print(pic,i)\n",
    "            img2 = pic.content #圖片裡的內容\n",
    "            imgpath = 'reddit_' + area + '\\\\' + keyword +'\\\\' + n #存成jpg檔\n",
    "            pic_out = open(imgpath,'wb') \n",
    "            pic_out.write(img2) #將get圖片存入img2\n",
    "            pic_out.close() #關閉檔案(很重要)\n",
    "            memenumber += 1\n",
    "\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            error.append(i)\n",
    "\n",
    "    # 指定CSV文件名\n",
    "    csv_file_name = 'reddit_' + area + '\\\\' + keyword +'\\\\' + 'error.csv'\n",
    "\n",
    "    with open(csv_file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # 對於一維列表，迭代每個元素，並將每個元素作為一行寫入\n",
    "        for element in error:\n",
    "            writer.writerow([element])  # 注意element被放在列表中，因為writerow()期望一個可迭代對象\n",
    "\n",
    "    print(f\"擷取失敗貼文已寫入 {csv_file_name}\")\n",
    "    print('關鍵字',keyword,'迷因數量',memenumber)\n",
    "    \n",
    "    allmeme += memenumber\n",
    "    time.sleep(10)\n",
    "print('共',allmeme,'個迷因')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 獲取「迷因」子版塊的熱門帖子\n",
    "#subreddit = reddit.subreddit('memes')\n",
    "abortion = subreddit.search('termination of pregnancy',limit=None)\n",
    "m = 0\n",
    "\n",
    "# 遍歷帖子並獲取相關數據\n",
    "for post in subreddit.hot(limit=None):\n",
    "    m+=1\n",
    "    title = post.title\n",
    "    author = post.author\n",
    "    created_date = post.created\n",
    "    created_date = datetime.fromtimestamp(created_date)\n",
    "    score = post.score\n",
    "    text = post.selftext\n",
    "    url = post.url\n",
    "    num_comments = post.num_comments\n",
    "    # 其他數據...\n",
    "\n",
    "    # 打印數據\n",
    "    print('p88',post)\n",
    "    print(f\"標題: {title}\")\n",
    "    print(f\"作者: {author}\")\n",
    "    print(f\"創建日期: {created_date}\")\n",
    "    print(f\"評分: {score}\")\n",
    "    print(f\"text: {text}\")\n",
    "    print(f\"評論數: {num_comments}\")\n",
    "    print(f\"url: {url}\")\n",
    "    # 其他數據...\n",
    "    print(\"=========================\")\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "# 你的Reddit客户端凭据\n",
    "client_id='xxxxxxx'\n",
    "client_secret='Nxxxxxxxx'\n",
    "user_agent='gxxxxxxxx5'\n",
    "\n",
    "# 准备请求\n",
    "data = {\n",
    "    'grant_type': 'client_credentials'\n",
    "}\n",
    "\n",
    "# 使用HTTP基本认证\n",
    "auth = HTTPBasicAuth(client_id, client_secret)\n",
    "\n",
    "# 设置合适的User-Agent\n",
    "headers = {\n",
    "    'User-Agent': user_agent\n",
    "}\n",
    "\n",
    "# 发送请求 https://www.reddit.com/api/v1/access_token\n",
    "response = requests.post('https://www.reddit.com/api/v1/access_token', data=data, auth=auth, headers=headers)\n",
    "\n",
    "# 解析响应\n",
    "if response.status_code == 200:\n",
    "    token_info = response.json()\n",
    "    access_token = token_info['access_token']\n",
    "    print(\"Access Token:\", access_token)\n",
    "else:\n",
    "    print(\"Failed to obtain token, status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c7c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# 假定已获取的认证令牌\n",
    "headers = {\n",
    "    'Authorization': 'xxxx',\n",
    "}\n",
    "\n",
    "# API参数\n",
    "params = {\n",
    "    'q': 'abortion subreddit:memes',\n",
    "    'limit': None,\n",
    "    'sort': 'relevance', # 或 'activity'\n",
    "    'show_users': 'false',\n",
    "}\n",
    "\n",
    "response = requests.get('https://www.reddit.com/subreddits/search.json', headers=headers, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # 处理响应数据\n",
    "    memes_about_abortion = response.json()\n",
    "    # 此处添加你的逻辑来处理或显示结果\n",
    "    posts = memes_about_abortion['data']['children']\n",
    "\n",
    "    for item in posts:\n",
    "        post = item['data']\n",
    "        title = post['title']\n",
    "        #author = post['author']\n",
    "        created_date = post['created']\n",
    "        # 将UNIX时间戳转换为datetime对象\n",
    "        created_date = datetime.fromtimestamp(created_date)\n",
    "        #score = post['score']\n",
    "        text = post.get('selftext', '')  # 使用get以避免KeyError，如果没有'selftext'则默认为空字符串\n",
    "        url = post['url']\n",
    "        #num_comments = post['num_comments']\n",
    "\n",
    "        # 尝试提取图片链接\n",
    "        image_url = None\n",
    "        if 'preview' in post and 'images' in post['preview']:\n",
    "            image_url = post['preview']['images'][0]['source']['url']\n",
    "        elif url.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "            image_url = url  # 如果URL直接指向一个图片文件\n",
    "            \n",
    "        # 打印信息，或者按需处理\n",
    "        print(f\"Title: {title}\")\n",
    "        #print(f\"Author: {author}\")\n",
    "        print(f\"Created Date: {created_date}\")\n",
    "        #print(f\"Score: {score}\")\n",
    "        print(f\"Text: {text}\")\n",
    "        print(f\"URL: {url}\")\n",
    "        #print(f\"Number of Comments: {num_comments}\")\n",
    "        if image_url:\n",
    "            print(f\"Image URL: {image_url}\")\n",
    "        print(\"------------------------------------------------------\")\n",
    "else:\n",
    "    print('请求失败:', response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974e57e-c77d-46dc-bb85-defe796eabb1",
   "metadata": {},
   "source": [
    "API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff25a6-7581-4f3c-8653-f4e720d3eac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
